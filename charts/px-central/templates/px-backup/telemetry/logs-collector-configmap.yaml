{{/* PX-Backup Telemetry Logs Collector ConfigMaps */}}
{{- $pxBackupEnabled := .Values.pxbackup.enabled | default false }}
{{- $telemetryEnabled := .Values.pxbackup.telemetry.enabled | default false }}
{{- $logsEnabled := .Values.pxbackup.telemetry.logsCollector.enabled | default true }}
{{- if and (eq $pxBackupEnabled true) (eq $telemetryEnabled true) (eq $logsEnabled true) }}
---
# Log Collection Script
apiVersion: v1
kind: ConfigMap
metadata:
  name: px-backup-telemetry-log-collector-script
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/component: px-backup-telemetry
    app.kubernetes.io/name: logs-collector
{{- include "px-central.labels" . | nindent 4 }}
data:
  collect-logs.sh: |
    #!/bin/bash
    # PX-Backup Telemetry Log Collector - Improved with timeout, retry, and error handling
    # This script collects logs from PX-Backup pods and reporting data, then uploads to Pure1

    # Disable exit-on-error globally (we handle errors per-function)
    set +e
    # Enable undefined variable detection and pipeline error detection
    set -uo pipefail

    #############################################################################
    # Configuration Variables
    #############################################################################
    LOG_DIR="/var/cores"
    NAMESPACE="{{ .Release.Namespace }}"
    PXBACKUP_POD_LABEL="app.kubernetes.io/part-of=px-backup"
    INTERVAL={{ .Values.pxbackup.telemetry.logsCollector.collectionInterval | default 3600 }}
    EXCLUDE_PATTERNS="postgresql|mysql|frontend|post-install|maintenance-repo|prometheus|alertmanager|telemetry"

    # Startup delay to allow pods to stabilize after helm upgrade (seconds)
    # This prevents the first collection from running before px-backup pod is fully ready
    STARTUP_DELAY={{ .Values.pxbackup.telemetry.logsCollector.startupDelay | default 60 }}

    # Timeout configuration
    CURL_CONNECT_TIMEOUT=10
    CURL_MAX_TIME=30
    GRPCURL_TIMEOUT=30
    MIN_DISK_SPACE_MB=1000

    # Shutdown flag for graceful termination
    SHUTDOWN=0

    #############################################################################
    # Logging Functions
    #############################################################################
    log_info() {
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] INFO: $*"
    }

    log_warn() {
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] WARN: $*" >&2
    }

    log_error() {
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $*" >&2
    }

    log_debug() {
        if [ "${DEBUG:-0}" = "1" ]; then
            echo "[$(date +'%Y-%m-%d %H:%M:%S')] DEBUG: $*" >&2
        fi
    }

    #############################################################################
    # Signal Handling for Graceful Shutdown
    #############################################################################
    handle_signal() {
        log_info "Received shutdown signal, finishing current collection..."
        SHUTDOWN=1
    }

    trap 'handle_signal' SIGTERM SIGINT SIGHUP

    #############################################################################
    # Input Validation
    #############################################################################
    validate_environment() {
        log_info "Validating environment..."

        # Validate required variables are set
        : "${LOG_DIR:?LOG_DIR is not set}"
        : "${NAMESPACE:?NAMESPACE is not set}"
        : "${PXBACKUP_POD_LABEL:?PXBACKUP_POD_LABEL is not set}"
        : "${INTERVAL:?INTERVAL is not set}"

        # Check Kubernetes environment variables
        log_debug "KUBERNETES_SERVICE_HOST: ${KUBERNETES_SERVICE_HOST:-NOT SET}"
        log_debug "KUBERNETES_SERVICE_PORT: ${KUBERNETES_SERVICE_PORT:-NOT SET}"

        # Validate INTERVAL is a positive number >= 60
        if ! [[ "$INTERVAL" =~ ^[0-9]+$ ]] || [ "$INTERVAL" -lt 60 ]; then
            log_error "INTERVAL must be a positive number >= 60, got: $INTERVAL"
            exit 1
        fi

        # Create and validate log directory
        if ! mkdir -p "$LOG_DIR" 2>/dev/null; then
            log_error "Failed to create log directory: $LOG_DIR"
            exit 1
        fi

        if [ ! -w "$LOG_DIR" ]; then
            log_error "Log directory is not writable: $LOG_DIR"
            exit 1
        fi

        # Check if kubectl is available
        if ! command -v kubectl &> /dev/null; then
            log_error "kubectl not found in PATH"
            exit 1
        fi

        # Check if jq is available
        if ! command -v jq &> /dev/null; then
            log_error "jq not found in PATH"
            exit 1
        fi

        log_info "Environment validation successful"
        log_info "  Log directory: $LOG_DIR"
        log_info "  Namespace: $NAMESPACE"
        log_info "  PX-Backup pod label: $PXBACKUP_POD_LABEL"
        log_info "  Collection interval: ${INTERVAL}s"
        log_info "  Exclude patterns: $EXCLUDE_PATTERNS"
    }

    #############################################################################
    # Disk Space Management
    #############################################################################
    check_disk_space() {
        local available_mb
        available_mb=$(df -m "$LOG_DIR" 2>/dev/null | awk 'NR==2 {print $4}')

        if [ -z "$available_mb" ]; then
            log_warn "Unable to check disk space for $LOG_DIR"
            return 0
        fi

        if [ "$available_mb" -lt "$MIN_DISK_SPACE_MB" ]; then
            log_warn "Low disk space: ${available_mb}MB available (minimum: ${MIN_DISK_SPACE_MB}MB)"

            # Try to clean up old files (older than 7 days)
            log_info "Attempting to clean up old log files..."
            local cleaned=0
            cleaned=$(find "$LOG_DIR" -name "px-backup-logs-*.log.gz" -mtime +7 -delete -print 2>/dev/null | wc -l)
            cleaned=$((cleaned + $(find "$LOG_DIR" -name "px-backup-reporting-*.log.gz" -mtime +7 -delete -print 2>/dev/null | wc -l)))

            if [ "$cleaned" -gt 0 ]; then
                log_info "Cleaned up $cleaned old log files"
            fi

            # Check again after cleanup
            available_mb=$(df -m "$LOG_DIR" 2>/dev/null | awk 'NR==2 {print $4}')
            if [ "$available_mb" -lt "$MIN_DISK_SPACE_MB" ]; then
                log_error "Still low on disk space after cleanup: ${available_mb}MB"
                return 1
            fi
        fi

        log_debug "Disk space OK: ${available_mb}MB available"
        return 0
    }



    #############################################################################
    # grpcurl Installation with Error Handling
    #############################################################################
    install_grpcurl() {
        if command -v grpcurl &> /dev/null; then
            log_debug "grpcurl already installed"
            return 0
        fi

        log_info "Installing grpcurl..."

        local grpcurl_version="1.8.9"
        local grpcurl_url="https://github.com/fullstorydev/grpcurl/releases/download/v${grpcurl_version}/grpcurl_${grpcurl_version}_linux_x86_64.tar.gz"
        local install_dir="/tmp/grpcurl"

        if ! mkdir -p "$install_dir" 2>/dev/null; then
            log_error "Failed to create grpcurl install directory: $install_dir"
            return 1
        fi

        # Download with retries and error checking
        local max_retries=3
        local retry=0
        while [ $retry -lt $max_retries ]; do
            if curl -fsSL --connect-timeout 10 --max-time 60 "$grpcurl_url" | tar xz -C "$install_dir" 2>/dev/null; then
                break
            fi
            retry=$((retry + 1))
            if [ $retry -lt $max_retries ]; then
                log_warn "grpcurl download failed (attempt $retry/$max_retries), retrying..."
                sleep 5
            fi
        done

        if [ $retry -eq $max_retries ]; then
            log_error "Failed to download grpcurl after $max_retries attempts"
            return 1
        fi

        if ! chmod +x "$install_dir/grpcurl" 2>/dev/null; then
            log_error "Failed to make grpcurl executable"
            return 1
        fi

        export PATH="$install_dir:$PATH"

        # Verify installation
        if ! command -v grpcurl &> /dev/null; then
            log_error "grpcurl installation failed - binary not found in PATH"
            return 1
        fi

        log_info "grpcurl installed successfully"
        return 0
    }

    #############################################################################
    # Log Collection Functions
    #############################################################################
    collect_pod_logs() {
        local pod="$1"
        local log_file="$2"
        local since_seconds="$3"

        log_debug "Collecting logs from pod: $pod"

        # Check if pod exists and get its status
        local pod_status
        pod_status=$(kubectl get pod -n "$NAMESPACE" "$pod" -o jsonpath='{.status.phase}' 2>/dev/null)
        local exit_code=$?

        if [ $exit_code -ne 0 ]; then
            log_warn "Failed to get pod status for: $pod"
            return 1
        fi

        if [ -z "$pod_status" ]; then
            log_warn "Pod not found: $pod"
            return 1
        fi

        if [ "$pod_status" != "Running" ]; then
            log_warn "Pod is not running (status: $pod_status), skipping: $pod"
            return 1
        fi

        # Check if pod has multiple containers
        local containers
        containers=$(kubectl get pod -n "$NAMESPACE" "$pod" -o jsonpath='{.spec.containers[*].name}' 2>/dev/null)
        local container_count=$(echo "$containers" | wc -w)

        # Collect logs - handle multi-container pods
        local kubectl_cmd="kubectl logs -n \"$NAMESPACE\" \"$pod\" --since=\"${since_seconds}s\""

        if [ "$container_count" -gt 1 ]; then
            log_debug "Pod has $container_count containers, collecting from all containers"
            kubectl_cmd="$kubectl_cmd --all-containers=true --prefix=true"
        fi

        if eval "$kubectl_cmd" > "$log_file" 2>/dev/null; then
            # Check if log file has content
            if [ -s "$log_file" ]; then
                return 0
            else
                log_debug "Log file is empty for pod: $pod"
                rm -f "$log_file"
                return 1
            fi
        else
            log_error "Failed to collect logs from pod: $pod"
            rm -f "$log_file"
            return 1
        fi
    }

    collect_logs() {
        local timestamp
        timestamp=$(date +%Y%m%d%H)

        log_info "Collecting logs with timestamp $timestamp"

        # Check disk space before collection
        if ! check_disk_space; then
            log_error "Skipping log collection due to low disk space"
            return 1
        fi

        # Get all pods matching the label selector
        local all_pods
        all_pods=$(kubectl get pods -n "$NAMESPACE" -l "$PXBACKUP_POD_LABEL" -o jsonpath='{.items[*].metadata.name}')

        if [ $? -ne 0 ] || [ -z "$all_pods" ]; then
            log_warn "No pods found matching label: $PXBACKUP_POD_LABEL"
            return 0
        fi

        log_info "Found pods: $all_pods"

        # Filter out excluded pods based on exclude patterns
        local filtered_pods=""
        local excluded_count=0
        local included_count=0

        for pod in $all_pods; do
            # Check if pod matches any exclude pattern
            if echo "$pod" | grep -qE "$EXCLUDE_PATTERNS"; then
                log_debug "Excluding pod: $pod (matches exclude pattern)"
                excluded_count=$((excluded_count + 1))
            else
                filtered_pods="$filtered_pods $pod"
                included_count=$((included_count + 1))
            fi
        done

        log_info "Pods to collect: $included_count, Excluded: $excluded_count"

        if [ -z "$filtered_pods" ]; then
            log_warn "No pods remaining after filtering"
            return 1
        fi

        # Collect logs from each pod into separate files
        local success_count=0
        local fail_count=0

        for pod in $filtered_pods; do
            local log_file="${LOG_DIR}/px-backup-logs-${pod}-${timestamp}.log"

            if collect_pod_logs "$pod" "$log_file" "$INTERVAL"; then
                # Compress the log file
                if gzip -f "$log_file" 2>/dev/null; then
                    local file_size
                    file_size=$(ls -lh "${log_file}.gz" 2>/dev/null | awk '{print $5}')
                    log_info "Created: ${log_file}.gz (${file_size})"
                    success_count=$((success_count + 1))
                else
                    log_error "Failed to compress log file: $log_file"
                    rm -f "$log_file"
                    fail_count=$((fail_count + 1))
                fi
            else
                fail_count=$((fail_count + 1))
            fi
        done

        log_info "Log collection completed: $success_count succeeded, $fail_count failed"
        return 0
    }

    #############################################################################
    # Reporting Data Collection Functions
    #############################################################################
    collect_reporting_data() {
        local timestamp
        timestamp=$(date +%Y%m%d%H)
        local reporting_file="${LOG_DIR}/px-backup-reporting-${timestamp}.log"

        log_info "Collecting reporting data with timestamp $timestamp"

        # Get px-backup pod name - use specific label to get the main px-backup pod
        local px_backup_pod
        px_backup_pod=$(kubectl get pods -n "$NAMESPACE" -l "app=px-backup" -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)

        if [ $? -ne 0 ] || [ -z "$px_backup_pod" ]; then
            log_warn "No px-backup pod found, skipping reporting data collection"
            return 1
        fi

        log_info "Fetching reporting data from pod: $px_backup_pod"

        # Check if pod is ready
        local pod_ready
        pod_ready=$(kubectl get pod -n "$NAMESPACE" "$px_backup_pod" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null)

        if [ "$pod_ready" != "True" ]; then
            log_warn "px-backup pod is not ready, skipping reporting data collection"
            return 1
        fi

        # Fetch reporting data with error handling
        local temp_file="${reporting_file}.tmp"

        # Execute curl inside the pod with timeout
        if kubectl exec -n "$NAMESPACE" "$px_backup_pod" -- \
            curl -f -sS \
            --connect-timeout "$CURL_CONNECT_TIMEOUT" \
            --max-time "$CURL_MAX_TIME" \
            http://localhost:10001/v1/reporting/data > "$temp_file" 2>/dev/null; then

            # Extract json_data field with jq
            if jq -r '.json_data' "$temp_file" > "$reporting_file" 2>/dev/null; then
                # Validate that we got valid JSON
                if [ -s "$reporting_file" ] && jq empty "$reporting_file" 2>/dev/null; then
                    # Compress the reporting file
                    if gzip -f "$reporting_file" 2>/dev/null; then
                        local file_size
                        file_size=$(ls -lh "${reporting_file}.gz" 2>/dev/null | awk '{print $5}')
                        log_info "Created: ${reporting_file}.gz (${file_size})"
                        rm -f "$temp_file"
                        return 0
                    else
                        log_error "Failed to compress reporting file"
                        rm -f "$temp_file" "$reporting_file"
                        return 1
                    fi
                else
                    log_error "Extracted data is not valid JSON or is empty"
                    rm -f "$temp_file" "$reporting_file"
                    return 1
                fi
            else
                log_error "Failed to extract json_data with jq"
                rm -f "$temp_file" "$reporting_file"
                return 1
            fi
        else
            log_error "Failed to fetch reporting data from API"
            rm -f "$temp_file"
            return 1
        fi
    }

    #############################################################################
    # Upload Trigger Function
    #############################################################################
    trigger_upload() {
        log_info "Triggering log upload via gRPC..."

        # Capture grpcurl response for logging
        local response
        response=$(timeout "${GRPCURL_TIMEOUT}s" grpcurl -plaintext localhost:9090 \
            com.purestorage.parts.loguploader.LogUploadService/UploadLog 2>&1)
        local exit_code=$?

        if [ $exit_code -eq 0 ]; then
            log_info "Upload triggered successfully. Response: $response"
            return 0
        else
            log_warn "Failed to trigger upload (exit code: $exit_code). Response: $response"
            return 1
        fi
    }

    #############################################################################
    # Cleanup Function - Remove old uploaded files
    #############################################################################
    cleanup_old_files() {
        log_info "Cleaning up old log files..."

        # Remove files older than 3 days (uploaded files should be cleaned up)
        # This prevents disk space issues since log-upload-service doesn't delete files
        local cleanup_age_days=3
        local cleaned_count=0

        # Find and delete old .gz files
        local old_files
        old_files=$(find "$LOG_DIR" -name "px-backup-logs-*.log.gz" -mtime +$cleanup_age_days 2>/dev/null)

        if [ -n "$old_files" ]; then
            while IFS= read -r file; do
                if rm -f "$file" 2>/dev/null; then
                    log_debug "Deleted old file: $file"
                    cleaned_count=$((cleaned_count + 1))
                fi
            done <<< "$old_files"
        fi

        # Also clean up old reporting files
        old_files=$(find "$LOG_DIR" -name "px-backup-reporting-*.log.gz" -mtime +$cleanup_age_days 2>/dev/null)

        if [ -n "$old_files" ]; then
            while IFS= read -r file; do
                if rm -f "$file" 2>/dev/null; then
                    log_debug "Deleted old file: $file"
                    cleaned_count=$((cleaned_count + 1))
                fi
            done <<< "$old_files"
        fi

        if [ $cleaned_count -gt 0 ]; then
            log_info "Cleaned up $cleaned_count old log files (older than ${cleanup_age_days} days)"
        else
            log_debug "No old files to clean up"
        fi

        return 0
    }

    #############################################################################
    # Main Execution
    #############################################################################
    main() {
        log_info "PX-Backup Telemetry Log Collector starting..."

        # Validate environment
        validate_environment

        # Install grpcurl
        if ! install_grpcurl; then
            log_error "FATAL: Cannot proceed without grpcurl"
            exit 1
        fi

        log_info "Initialization complete"

        # Startup delay to allow all pods to stabilize after helm upgrade
        if [ "$STARTUP_DELAY" -gt 0 ]; then
            log_info "Waiting ${STARTUP_DELAY}s for pods to stabilize after startup..."
            local elapsed=0
            while [ $elapsed -lt $STARTUP_DELAY ] && [ $SHUTDOWN -eq 0 ]; do
                sleep 10
                elapsed=$((elapsed + 10))
            done

            if [ $SHUTDOWN -eq 1 ]; then
                log_info "Shutdown requested during startup delay"
                exit 0
            fi
            log_info "Startup delay complete, beginning collection loop"
        fi

        # Main collection loop with graceful shutdown
        while [ $SHUTDOWN -eq 0 ]; do
            log_info "=== Starting collection cycle ==="

            # Collect logs from pods
            collect_logs

            # Collect reporting data
            collect_reporting_data

            # Trigger upload and track status
            if trigger_upload; then
                log_info "Upload status: SUCCESS"
                # Clean up old files after successful upload
                cleanup_old_files
            else
                log_warn "Upload status: FAILED - will retry next cycle"
            fi

            # Sleep with interrupt capability
            log_info "Sleeping for ${INTERVAL} seconds..."
            local elapsed=0
            while [ $elapsed -lt $INTERVAL ] && [ $SHUTDOWN -eq 0 ]; do
                sleep 10
                elapsed=$((elapsed + 10))
            done
        done

        log_info "Shutdown complete"
        exit 0
    }

    # Start main execution
    main
---
# Envoy Proxy Configuration for Logs Upload
apiVersion: v1
kind: ConfigMap
metadata:
  name: px-backup-telemetry-logs-envoy-config
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/component: px-backup-telemetry
    app.kubernetes.io/name: logs-collector
{{- include "px-central.labels" . | nindent 4 }}
data:
  envoy-config.yaml: |
    admin:
      address:
        socket_address:
          address: 127.0.0.1
          port_value: 9901
    # Node identification (required for SDS)
    node:
      id: "id_logs"
      cluster: "cluster_logs"
    static_resources:
      listeners:
      - name: listener_logs
        address:
          socket_address:
            address: 127.0.0.1
            port_value: 12002
        filter_chains:
        - filters:
          - name: envoy.filters.network.http_connection_manager
            typed_config:
              "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
              stat_prefix: ingress_http
              access_log:
              - name: envoy.access_loggers.stdout
                typed_config:
                  "@type": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog
              http_filters:
              - name: envoy.filters.http.router
                typed_config:
                  "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
              route_config:
                name: local_route
                virtual_hosts:
                - name: local_service
                  domains: ["*"]
                  routes:
                  - match:
                      prefix: "/"
                    # Add headers to identify the product and cluster
                    request_headers_to_add:
                    # Product name - using "portworx" (same as PX-Enterprise)
                    - header:
                        key: "product-name"
                        value: "portworx"
                    # Appliance ID - using appliance-id from ConfigMap
                    - header:
                        key: "appliance-id"
{{- $telemetryConfig := lookup "v1" "ConfigMap" .Release.Namespace "px-backup-telemetry-config" }}
{{- if $telemetryConfig }}
                        value: {{ index $telemetryConfig.data "appliance-id" | quote }}
{{- else }}
                        value: "unknown"
{{- end }}
                    # Component serial number - identifies this as log upload
                    - header:
                        key: "component-sn"
                        value: "px-backup-log-upload"
                    # Product version - PX-Backup version
                    - header:
                        key: "product-version"
                        value: {{ .Values.pxbackup.version | quote }}
                    route:
                      host_rewrite_literal: {{ .Values.pxbackup.telemetry.restEndpoint }}
                      cluster: cluster_cloud_support
      clusters:
      - name: cluster_cloud_support
        type: STRICT_DNS
        dns_lookup_family: V4_ONLY
        lb_policy: ROUND_ROBIN
        load_assignment:
          cluster_name: cluster_cloud_support
          endpoints:
          - lb_endpoints:
            - endpoint:
                address:
                  socket_address:
                    address: {{ .Values.pxbackup.telemetry.restEndpoint }}
                    port_value: 443
        transport_socket:
          name: envoy.transport_sockets.tls
          typed_config:
            "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext
            sni: {{ .Values.pxbackup.telemetry.restEndpoint }}
            common_tls_context:
              # Client certificate configuration using SDS
              tls_certificate_sds_secret_configs:
                name: tls_sds
                sds_config:
                  # Path to SDS configuration file
                  path: /etc/envoy/tls_certificate_sds_secret.yaml
              # Server certificate validation
              validation_context:
                trusted_ca:
                  filename: /etc/ssl/certs/ca-certificates.crt
                match_typed_subject_alt_names:
                - san_type: DNS
                  matcher:
                    exact: {{ .Values.pxbackup.telemetry.restEndpoint }}
---
# SDS Configuration for Dynamic Certificate Loading
apiVersion: v1
kind: ConfigMap
metadata:
  name: px-backup-telemetry-logs-envoy-sds-config
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/component: px-backup-telemetry
    app.kubernetes.io/name: logs-collector
{{- include "px-central.labels" . | nindent 4 }}
data:
  tls_certificate_sds_secret.yaml: |
    resources:
    - "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.Secret
      name: tls_sds
      tls_certificate:
        certificate_chain:
          filename: /appliance-cert/cert
        private_key:
          filename: /appliance-cert/private_key
---
# Log Upload Service Configuration (ccm.properties)
apiVersion: v1
kind: ConfigMap
metadata:
  name: px-backup-telemetry-logs-upload-config
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/component: px-backup-telemetry
    app.kubernetes.io/name: logs-collector
{{- include "px-central.labels" . | nindent 4 }}
data:
  ccm.properties: |
    {
      "product_name": "portworx",
      "port": "9090",
      "envoy_port": "12002",
      "logupload": {
        "logfile_patterns": [
          "/var/cores/px-backup-logs-*.log.gz",
          "/var/cores/px-backup-reporting-*.log.gz"
        ],
        "phonehome_hour_range": 744,
        "always_scan_range_days": 7,
        "max_retry_per_hour": 5
      }
    }
{{- end }}

